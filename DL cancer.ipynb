{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This librarys is to work with matrices\n",
    "import pandas as pd \n",
    "# This librarys is to work with vectors\n",
    "import numpy as np\n",
    "# This library is to create some graphics algorithmn\n",
    "import seaborn as sns\n",
    "# to render the graphs\n",
    "import matplotlib.pyplot as plt\n",
    "# import module to set some ploting parameters\n",
    "from matplotlib import rcParams\n",
    "# Library to work with Regular Expressions\n",
    "import re\n",
    "#Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# This function makes the plot directly on browser\n",
    "%matplotlib inline\n",
    "\n",
    "# Seting a universal figure size \n",
    "rcParams['figure.figsize'] = 10,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.301724</td>\n",
       "      <td>27.582111</td>\n",
       "      <td>97.793103</td>\n",
       "      <td>10.012086</td>\n",
       "      <td>2.694988</td>\n",
       "      <td>26.615080</td>\n",
       "      <td>10.180874</td>\n",
       "      <td>14.725966</td>\n",
       "      <td>534.647000</td>\n",
       "      <td>1.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.112766</td>\n",
       "      <td>5.020136</td>\n",
       "      <td>22.525162</td>\n",
       "      <td>10.067768</td>\n",
       "      <td>3.642043</td>\n",
       "      <td>19.183294</td>\n",
       "      <td>6.843341</td>\n",
       "      <td>12.390646</td>\n",
       "      <td>345.912663</td>\n",
       "      <td>0.499475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.370000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.432000</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>4.311000</td>\n",
       "      <td>1.656020</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>45.843000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>22.973205</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>4.359250</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>12.313675</td>\n",
       "      <td>5.474282</td>\n",
       "      <td>6.881763</td>\n",
       "      <td>269.978250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>27.662416</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5.924500</td>\n",
       "      <td>1.380939</td>\n",
       "      <td>20.271000</td>\n",
       "      <td>8.352692</td>\n",
       "      <td>10.827740</td>\n",
       "      <td>471.322500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>31.241442</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>11.189250</td>\n",
       "      <td>2.857787</td>\n",
       "      <td>37.378300</td>\n",
       "      <td>11.815970</td>\n",
       "      <td>17.755207</td>\n",
       "      <td>700.085000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>38.578759</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>58.460000</td>\n",
       "      <td>25.050342</td>\n",
       "      <td>90.280000</td>\n",
       "      <td>38.040000</td>\n",
       "      <td>82.100000</td>\n",
       "      <td>1698.440000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         BMI     Glucose     Insulin        HOMA      Leptin  \\\n",
       "count  116.000000  116.000000  116.000000  116.000000  116.000000  116.000000   \n",
       "mean    57.301724   27.582111   97.793103   10.012086    2.694988   26.615080   \n",
       "std     16.112766    5.020136   22.525162   10.067768    3.642043   19.183294   \n",
       "min     24.000000   18.370000   60.000000    2.432000    0.467409    4.311000   \n",
       "25%     45.000000   22.973205   85.750000    4.359250    0.917966   12.313675   \n",
       "50%     56.000000   27.662416   92.000000    5.924500    1.380939   20.271000   \n",
       "75%     71.000000   31.241442  102.000000   11.189250    2.857787   37.378300   \n",
       "max     89.000000   38.578759  201.000000   58.460000   25.050342   90.280000   \n",
       "\n",
       "       Adiponectin    Resistin        MCP.1  Classification  \n",
       "count   116.000000  116.000000   116.000000      116.000000  \n",
       "mean     10.180874   14.725966   534.647000        1.551724  \n",
       "std       6.843341   12.390646   345.912663        0.499475  \n",
       "min       1.656020    3.210000    45.843000        1.000000  \n",
       "25%       5.474282    6.881763   269.978250        1.000000  \n",
       "50%       8.352692   10.827740   471.322500        2.000000  \n",
       "75%      11.815970   17.755207   700.085000        2.000000  \n",
       "max      38.040000   82.100000  1698.440000        2.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data.txt',delimiter='\\t')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This input data is consisted of (116, 9)\n",
      "This dataset is consisted of (116, 10)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Classification',1)\n",
    "Y = df.Classification\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.1)\n",
    "print(\"This input data is consisted of\",X.shape)\n",
    "print(\"This dataset is consisted of\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f24d34fea4a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "model = Sequential()\n",
    "\n",
    "# Inputing the first layer with input dimensions\n",
    "model.add(Dense(18, \n",
    "                activation='relu',  \n",
    "                input_dim=9,\n",
    "                kernel_initializer='uniform'))\n",
    "#The argument being passed to each Dense layer (18) is the number of hidden units of the layer. \n",
    "# A hidden unit is a dimension in the representation space of the layer.\n",
    "\n",
    "#Stacks of Dense layers with relu activations can solve a wide range of problems\n",
    "#(including sentiment classification), and you’ll likely use them frequently.\n",
    "\n",
    "# Adding an Dropout layer to previne from overfitting\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "#adding second hidden layer \n",
    "model.add(Dense(32,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "# Adding an Dropout layer to previne from overfitting\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "#adding second hidden layer \n",
    "model.add(Dense(32,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "\n",
    "# adding the output layer that is binary [0,1]\n",
    "model.add(Dense(1,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid'))\n",
    "#With such a scalar sigmoid output on a binary classification problem, the loss\n",
    "#function you should use is binary_crossentropy\n",
    "\n",
    "#Visualizing the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an Stochastic Gradient Descent\n",
    "sgd = SGD(lr = 0.01, momentum = 0.9)\n",
    "\n",
    "# Compiling our model\n",
    "model.compile(optimizer = RMSprop(), \n",
    "                   loss = 'binary_crossentropy', \n",
    "                   metrics = ['accuracy'])\n",
    "#optimizers list\n",
    "#optimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, \n",
    "               batch_size = 30, \n",
    "               epochs = 30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_train, y_train, batch_size=30)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.20, \n",
    "                    epochs=180, batch_size=10, verbose=0)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
